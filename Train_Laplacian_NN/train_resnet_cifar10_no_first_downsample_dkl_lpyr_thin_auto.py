import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
from torchvision.models import resnet18, ResNet18_Weights
import os
from tqdm import tqdm
from torchsummary import summary
import math
from lpyr_dec import *
import torch.nn.functional as F
from torchvision.models.resnet import BasicBlock
import copy
import json

# Viewing Condition Setting
peak_luminance = 500.0
checkpoint_path = f'../HVS_for_better_NN_pth/best_resnet18_cifar10_no_first_downsample_dkl_lpyr_thin_pl{peak_luminance}_3.pth'
load_pretrained_weights = False
resolution = [3840,2160]
diagonal_size_inches = 55
viewing_distance_meters = 1

ar = resolution[0]/resolution[1]
height_mm = math.sqrt( (diagonal_size_inches*25.4)**2 / (1+ar**2) )
display_size_m = (ar*height_mm/1000, height_mm/1000)
pix_deg = 2 * math.degrees(math.atan(0.5 * display_size_m[0] / resolution[0] / viewing_distance_meters))
display_ppd = 1 / pix_deg

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
lpyr = laplacian_pyramid_simple(32, 32, display_ppd, device)
target_acc = 93.9
save_log = {}


# --- âœ… DKLè½¬æ¢ç›¸å…³çŸ©é˜µ ---
LMS2006_to_DKLd65 = torch.tensor([
  [1.000000000000000,   1.000000000000000,                   0],
  [1.000000000000000,  -2.311130179947035,                   0],
  [-1.000000000000000,  -1.000000000000000,  50.977571328718781]
], dtype=torch.float32)
XYZ_to_LMS2006 = torch.tensor([
   [0.187596268556126,   0.585168649077728,  -0.026384263306304],
   [-0.133397430663221,   0.405505777260049,   0.034502127690364],
   [0.000244379021663,  -0.000542995890619,   0.019406849066323]
], dtype=torch.float32)

# --- âœ… sRGB â†’ Linear RGB ---
def srgb_to_linear_rgb(srgb):
    """sRGB è½¬çº¿æ€§ RGB (gamma è§£ç )ï¼Œè¾“å…¥ [0, 1]ï¼Œè¾“å‡º [0, 1]"""
    threshold = 0.04045
    linear = torch.where(
        srgb <= threshold,
        srgb / 12.92,
        ((srgb + 0.055) / 1.055) ** 2.4
    )
    return linear

# --- âœ… Linear RGB â†’ XYZ (D65) ---
def linear_rgb_to_xyz(rgb):
    """çº¿æ€§ RGB â†’ XYZï¼ŒD65"""
    # ä½¿ç”¨ sRGB çš„ D65 åˆ° XYZ è½¬æ¢çŸ©é˜µ
    M = torch.tensor([[0.4124564, 0.3575761, 0.1804375],
                      [0.2126729, 0.7151522, 0.0721750],
                      [0.0193339, 0.1191920, 0.9503041]], dtype=rgb.dtype, device=rgb.device)
    rgb = rgb.permute(1, 2, 0)  # (C,H,W) â†’ (H,W,C)
    xyz = torch.tensordot(rgb, M.T, dims=1)  # (H,W,3)
    return xyz.permute(2, 0, 1)  # (3,H,W)

# --- âœ… XYZ â†’ LMS2006 ---
def xyz_to_lms2006(xyz):
    xyz = xyz.permute(1, 2, 0)  # C,H,W â†’ H,W,C
    lms = torch.tensordot(xyz, XYZ_to_LMS2006.T.to(xyz.device), dims=1)
    return lms.permute(2, 0, 1)

# --- âœ… LMS2006 â†’ DKL ---
def lms_to_dkl(lms):
    lms = lms.permute(1, 2, 0)  # C,H,W â†’ H,W,C
    dkl = torch.tensordot(lms, LMS2006_to_DKLd65.T.to(lms.device), dims=1)
    return dkl.permute(2, 0, 1)  # C,H,W

# --- âœ… æœ€ç»ˆ transformï¼ˆsRGB â†’ DKLï¼‰ ---
class RGBtoDKLTransform:
    def __init__(self, peak_luminance=500.0):
        self.peak_luminance = peak_luminance

    def __call__(self, tensor):
        tensor = srgb_to_linear_rgb(tensor)               # sRGB â†’ linear RGB
        tensor = linear_rgb_to_xyz(tensor) * self.peak_luminance  # â†’ XYZ (cd/mÂ²)
        tensor = xyz_to_lms2006(tensor)                   # â†’ LMS
        tensor = lms_to_dkl(tensor)                       # â†’ DKL
        return tensor

# æ›¿æ¢ä¸ºåŸå§‹å­—ç¬¦ä¸²é¿å… warning
# data_root = r'E:\Datasets\CIFAR10\data'
data_root = r'../Datasets/CIFAR10/data'

transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    RGBtoDKLTransform(peak_luminance=peak_luminance)  # âœ… DKL æ›¿æ¢ XYZ
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    RGBtoDKLTransform(peak_luminance=peak_luminance)
])

trainset = torchvision.datasets.CIFAR10(root=data_root, train=True, download=False, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)

testset = torchvision.datasets.CIFAR10(root=data_root, train=False, download=False, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)

def make_layer(block, in_planes, out_planes, blocks, stride=1):
    """è‡ªå®šä¹‰layeræ„é€ å‡½æ•°ä»¥å…¼å®¹ä¸åŒé€šé“æ•°"""
    downsample = None
    if stride != 1 or in_planes != out_planes:
        downsample = nn.Sequential(
            nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),
            nn.BatchNorm2d(out_planes),
        )

    layers = []
    layers.append(block(in_planes, out_planes, stride, downsample))
    for _ in range(1, blocks):
        layers.append(block(out_planes, out_planes))

    return nn.Sequential(*layers)

class PyramidResNet18(nn.Module):
    def __init__(self, num_classes=10, channel_net=[4, 64, 128, 256, 512]):
        super().__init__()
        base = resnet18(weights=None)
        self.channel = channel_net #æœ€åˆæ˜¯[64, 64, 128, 256, 512] #64-93.90%, 32-94.03%, 16-94.39%ï¼Œ 8-94.16%, 4-94.04%
        # base.conv1 = nn.Conv2d(6, 64, kernel_size=3, stride=1, padding=1, bias=False)  # è¾“å…¥ concat image + L0
        base.conv1 = nn.Conv2d(3, self.channel[0], kernel_size=3, stride=1, padding=1, bias=False)  # è¾“å…¥ concat image + L0
        base.maxpool = nn.Identity()

        self.conv1 = base.conv1
        self.bn1 = nn.BatchNorm2d(self.channel[0]) ###å§æ§½ï¼åè€Œ+0.4%çš„æ­£å‘å¢é•¿
        self.relu = base.relu
        self.maxpool = base.maxpool
        # self.layer1 = base.layer1

        self.layer1 = make_layer(BasicBlock, self.channel[0], self.channel[1], blocks=2, stride=1)
        self.layer2 = make_layer(BasicBlock, self.channel[1], self.channel[2], blocks=2, stride=2)
        self.layer3 = make_layer(BasicBlock, self.channel[2], self.channel[3], blocks=2, stride=2)
        self.layer4 = make_layer(BasicBlock, self.channel[3], self.channel[4], blocks=2, stride=2)
        self.avgpool = base.avgpool
        self.fc = nn.Linear(base.fc.in_features, num_classes)

        self.inject1 = nn.Conv2d(3, self.channel[0], 1)  # å°†pyr[1]ç¼–ç ä¸º gating
        self.inject2 = nn.Conv2d(3, self.channel[1], 1)
        self.inject3 = nn.Conv2d(3, self.channel[2], 1)
        self.inject4 = nn.Conv2d(3, self.channel[3], 1)

        self.gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),  # å…¨å±€æ± åŒ–ï¼Œä¿ç•™é€šé“ç»´åº¦
            nn.Sigmoid()  # è¾“å‡ºåœ¨ (0,1)ï¼Œç”¨äºé—¨æ§
        )

    def forward(self, x):
        _, pyr = lpyr.decompose(x, levels=4)
        # x = self.conv1(torch.cat([x, pyr[0]], dim=1))
        # x = self.layer1(x + self.inject1(F.interpolate(pyr[1], size=x.shape[-2:])))
        # x = self.layer2(x + self.inject2(F.interpolate(pyr[2], size=x.shape[-2:])))
        # x = self.layer3(x + self.inject3(F.interpolate(pyr[3], size=x.shape[-2:])))
        # x = self.layer4(x + self.inject4(F.interpolate(pyr[4], size=x.shape[-2:])))
        # x = self.avgpool(x)

        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))
        feat1 = self.inject1(F.interpolate(pyr[0], size=x.shape[-2:]))
        alpha1 = self.gate(feat1)
        x = self.layer1(x * alpha1) #è¿™æ ·æ“ä½œä¼¼ä¹æ²¡æœ‰ä»»ä½•çš„ç²¾åº¦æŸå¤±(-0.15%)
        # x = self.maxpool(self.relu(self.bn1(self.conv1(pyr[0])))) #ç›´æ¥ä½¿ç”¨pyr[0]ä¼šå¯¼è‡´-0.9%å·¦å³çš„ç²¾åº¦æŸå¤±
        # x = self.layer1(x + self.inject1(F.interpolate(pyr[1], size=x.shape[-2:]))) #ç›´æ¥ä½¿ç”¨pyr[1]ä¼šå¯¼è‡´-1.5%å·¦å³çš„ç²¾åº¦æŸå¤±
        feat2 = self.inject2(F.interpolate(pyr[1], size=x.shape[-2:]))
        alpha2 = self.gate(feat2)
        x = self.layer2(x * alpha2)

        feat3 = self.inject3(F.interpolate(pyr[2], size=x.shape[-2:]))
        alpha3 = self.gate(feat3)
        x = self.layer3(x * alpha3)

        feat4 = self.inject4(F.interpolate(pyr[3], size=x.shape[-2:]))
        alpha4 = self.gate(feat4)
        x = self.layer4(x * alpha4)
        x = self.avgpool(x)

        return self.fc(torch.flatten(x, 1))


def train(epoch, model, criterion, optimizer):
    torch.cuda.empty_cache()
    model.train()
    # lpyr = laplacian_pyramid_simple(resolution[0], resolution[1], display_ppd, device)
    running_loss = 0.0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"[Epoch {epoch}] Training Loss: {running_loss / len(trainloader):.3f}")

def test(epoch, model):
    torch.cuda.empty_cache()
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
    acc = 100. * correct / total
    print(f"[Epoch {epoch}] Test Accuracy: {acc:.2f}%")
    return acc

# è‡ªåŠ¨è°ƒæ•´ channel å„ç»´åº¦å€¼ä»¥æ»¡è¶³æœ€ä½å‡†ç¡®ç‡çº¦æŸ
def auto_tune_channels():
    original_channel = [16, 64, 128, 256, 512]
    best_channel = original_channel.copy()
    acc_history = []

    for idx in range(len(best_channel)):
        current = best_channel[idx] * 2
        print(f"\nğŸ” æ­£åœ¨ä¼˜åŒ–ç¬¬ {idx} ç»´ channelï¼ˆå½“å‰å€¼ï¼š{current//2}ï¼‰")
        while current > 3:
            # å€™é€‰æ–°å€¼
            candidate = current // 2
            if candidate < 3:
                break

            # æ„å»ºæ–°æ¨¡å‹
            candidate_channel = best_channel.copy()
            candidate_channel[idx] = candidate
            print(f" âœ  å°è¯• {candidate_channel}")

            model = PyramidResNet18(num_classes=10, channel_net=candidate_channel)
            model = model.to(device)
            summary(model, input_size=(3, 32, 32))

            if os.path.isfile(checkpoint_path) and load_pretrained_weights:
                print(f"âš¡ï¸ Loading pretrained weights from {checkpoint_path}")
                model.load_state_dict(torch.load(checkpoint_path, map_location=device))
            else:
                print("No pretrained weights found, training from scratch.")

            # summary(model, input_size=(3, 32, 32))

            criterion = nn.CrossEntropyLoss()
            optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)
            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

            # è®­ç»ƒæ¨¡å‹
            best_acc = 0
            for epoch in tqdm(range(1, 101)):
                print(f"Epoch {epoch}/100")
                train(epoch, model, criterion, optimizer)
                acc = test(epoch, model)
                if acc > best_acc:
                    best_acc = acc
                    print(f"âœ… New best accuracy {best_acc:.2f}%")
                scheduler.step()

            acc_history.append((candidate_channel.copy(), best_acc))
            print(f" âœ… å°è¯• channel {candidate_channel}ï¼Œå‡†ç¡®ç‡ï¼š{best_acc:.2f}%")

            # ä¿å­˜å‡†ç¡®ç‡åˆ°æ–‡ä»¶
            save_path = f"channel_{'_'.join(map(str, candidate_channel))}_acc_{best_acc:.2f}.txt"
            with open(save_path, 'w') as f:
                f.write(f"channel: {candidate_channel}\naccuracy: {best_acc:.2f}\n")

            if best_acc >= 94.0:
                best_channel[idx] = candidate
                current = candidate  # å°è¯•æ›´å°å€¼
            else:
                print(f" âŒ {candidate} å¤ªå°ï¼Œä¿æŒ {current}")
                break


    print("\nğŸ‰ æœ€ä¼˜é€šé“é…ç½®ï¼š", best_channel)
    return best_channel, acc_history


if __name__ == '__main__':
    best_config, history = auto_tune_channels()

# å°†åŸæœ¬è®­ç»ƒçš„RGBç©ºé—´å˜ä¸ºçº¿æ€§XYZç©ºé—´